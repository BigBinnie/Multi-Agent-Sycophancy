# GPT-3.5 Turbo model configuration
defaults:
  - _base_

model_id: gpt-3.5-turbo
config:
  maxTokenCount: 4096
  temperature: 0.7
