# Base model configuration for Llama models
model_id: null  # Will be overridden by specific model configs
config:
  maxTokenCount: 2048
  stopSequences: []
  temperature: 0.7
