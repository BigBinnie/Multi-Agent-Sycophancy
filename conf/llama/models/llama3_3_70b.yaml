# Llama 3.3 70B model configuration
model_id: meta-llama/Llama-3.3-70B-Instruct
config:
  maxTokenCount: 1024
  stopSequences: []
  temperature: 0.7
  local_model_path: models/Llama-3.3-70B-Instruct
  max_model_len: 8192
